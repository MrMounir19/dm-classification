{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "First the training data is preprocessed. The rows which contain missing values are filled with the most frequent value for that particular feature (column).\n",
    "Then all the category features are labeled using a LabelEncoder.\n",
    "Finally the data is splited in X (the features) and Y (the target label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mouni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "\n",
    "existing_customers = pd.read_excel(\"data/existing-customers.xlsx\", engine=\"openpyxl\")\n",
    "existing_customers = existing_customers.fillna(existing_customers.mode().iloc[0])\n",
    "to_label = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\", \"class\"]\n",
    "label_encoder = LabelEncoder()\n",
    "for label in to_label:\n",
    "    existing_customers[label] = label_encoder.fit_transform(existing_customers[label])\n",
    "\n",
    "X = existing_customers.drop([\"class\", \"RowID\"], axis=1)\n",
    "Y = existing_customers[\"class\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "\n",
    "Here a profit function is defined which makes use of the True and False positives to calculate an estimate of the profit that a particular classifier makes. A dataframe is created to save all the metrics for each classifier. Classifiers will be ranked based on highest profit this is because accuracy is not a good measure here since the data is highly imbalanced (75% of the data is <=50k) and all we care about is to make the highest profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "def profit(y_true, y_pred):\n",
    "    cfm = confusion_matrix(y_true, y_pred)\n",
    "    TN, FP, FN, TP = cfm.ravel()\n",
    "    profit = 0.1*TP*(980) + 0.05*FP*(-310) + (TP+FP)*(-10)\n",
    "    return profit\n",
    "profit_scorer = make_scorer(profit)\n",
    "\n",
    "scoring = {\n",
    "    'acc': 'accuracy',\n",
    "    'prec': 'precision',\n",
    "    'rec': 'recall',\n",
    "    'prof': profit_scorer\n",
    "}\n",
    "results = pd.DataFrame(columns=['Algorithm', 'Accuracy', 'Precision', 'Recall', 'Profit'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbors Classifiers\n",
    "First the KNeighbors classifier is used and a grid search (with 5-fold cross-validation) is used to find the best number of neighbors to use. 5 Neighbors gets the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "parameters = {\n",
    "    \"n_neighbors\": [1, 5, 11, 25, 51, 101]\n",
    "}\n",
    "GCV = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=parameters, scoring=scoring, refit='prof', cv=5)\n",
    "GCV.fit(X, Y)\n",
    "# Mean scores for the best parameter\n",
    "mean_acc = GCV.cv_results_['mean_test_acc'][GCV.best_index_]\n",
    "mean_prec = GCV.cv_results_['mean_test_prec'][GCV.best_index_]\n",
    "mean_rec = GCV.cv_results_['mean_test_rec'][GCV.best_index_]\n",
    "mean_prof = GCV.cv_results_['mean_test_prof'][GCV.best_index_]\n",
    "results.loc[len(results.index)] = ['KNeighborsClassifier', mean_acc, mean_prec, mean_rec, mean_prof]\n",
    "print(GCV.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "For the Decision Tree classifier I wanted to find which splitting criterion is the best. After using a GridSearch (with 5-fold cross-validation) the entropy criterion gets the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Decision Tree Classifier\n",
    "parameters = {\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "GCV = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=parameters, scoring=scoring, refit='prof', cv=5)\n",
    "GCV.fit(X, Y)\n",
    "# Mean scores for the best parameter\n",
    "mean_acc = GCV.cv_results_['mean_test_acc'][GCV.best_index_]\n",
    "mean_prec = GCV.cv_results_['mean_test_prec'][GCV.best_index_]\n",
    "mean_rec = GCV.cv_results_['mean_test_rec'][GCV.best_index_]\n",
    "mean_prof = GCV.cv_results_['mean_test_prof'][GCV.best_index_]\n",
    "results.loc[len(results.index)] = ['DecisionTreeClassifier', mean_acc, mean_prec, mean_rec, mean_prof]\n",
    "print(GCV.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Naive Bayes Classifier\n",
    "Since most of the features are categories I wanted to try this classifier and see how it performs. For this I did a 5-fold cross-validation with the default parameters and saved the average metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "# Categorical Naive Bayes\n",
    "scores = cross_validate(CategoricalNB(), X, Y, scoring=scoring, cv=5)\n",
    "# Mean scores\n",
    "mean_acc = np.average(scores['test_acc'])\n",
    "mean_prec = np.average(scores['test_prec'])\n",
    "mean_rec = np.average(scores['test_rec'])\n",
    "mean_prof = np.average(scores['test_prof'])\n",
    "results.loc[len(results.index)] = ['CategoricalNB', mean_acc, mean_prec, mean_rec, mean_prof]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier\n",
    "Here I wanted to boost the Decision Tree classifier with the AdaBoost Classifier. For this 50, 100 and 1000 estimators are tested. And as I was expecting a higher number of estimators gave a better result. I kept it to a max 1000 estimators because the computing times increase a lot if you use more estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "parameters = {\n",
    "    'n_estimators': [50, 100, 1000]\n",
    "}\n",
    "GCV = GridSearchCV(estimator=AdaBoostClassifier(), param_grid=parameters, scoring=scoring, refit='prof', cv=5)\n",
    "GCV.fit(X, Y)\n",
    "# Mean scores for the best parameter\n",
    "mean_acc = GCV.cv_results_['mean_test_acc'][GCV.best_index_]\n",
    "mean_prec = GCV.cv_results_['mean_test_prec'][GCV.best_index_]\n",
    "mean_rec = GCV.cv_results_['mean_test_rec'][GCV.best_index_]\n",
    "mean_prof = GCV.cv_results_['mean_test_prof'][GCV.best_index_]\n",
    "results.loc[len(results.index)] = ['AdaBoostClassifier', mean_acc, mean_prec, mean_rec, mean_prof]\n",
    "print(GCV.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Classifier\n",
    "For this last classifier again I wanted to see if we could get better results using multiple Decision Trees. Random Forest is the perfect algorithm for this, I tested three different number of trees 100, 200 and 1000 again as I was expecting higher number of estimators gave better results but with the cost of higher computation times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "parameters = {\n",
    "    'n_estimators': [100, 200, 1000]\n",
    "}\n",
    "GCV = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameters, scoring=scoring, refit='prof', cv=5)\n",
    "GCV.fit(X, Y)\n",
    "# Mean scores for the best parameter\n",
    "mean_acc = GCV.cv_results_['mean_test_acc'][GCV.best_index_]\n",
    "mean_prec = GCV.cv_results_['mean_test_prec'][GCV.best_index_]\n",
    "mean_rec = GCV.cv_results_['mean_test_rec'][GCV.best_index_]\n",
    "mean_prof = GCV.cv_results_['mean_test_prof'][GCV.best_index_]\n",
    "results.loc[len(results.index)] = ['RandomForestClassifier', mean_acc, mean_prec, mean_rec, mean_prof]\n",
    "print(GCV.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the average metrics of each classifier (with the best parameters) during the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.838887</td>\n",
       "      <td>0.680704</td>\n",
       "      <td>0.623775</td>\n",
       "      <td>74372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.818372</td>\n",
       "      <td>0.624951</td>\n",
       "      <td>0.614593</td>\n",
       "      <td>70065.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>0.858727</td>\n",
       "      <td>0.736408</td>\n",
       "      <td>0.643924</td>\n",
       "      <td>79641.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.870582</td>\n",
       "      <td>0.783908</td>\n",
       "      <td>0.638696</td>\n",
       "      <td>81097.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.850158</td>\n",
       "      <td>0.716068</td>\n",
       "      <td>0.626197</td>\n",
       "      <td>76481.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Accuracy  Precision    Recall   Profit\n",
       "0    KNeighborsClassifier  0.838887   0.680704  0.623775  74372.0\n",
       "1  DecisionTreeClassifier  0.818372   0.624951  0.614593  70065.2\n",
       "2           CategoricalNB  0.858727   0.736408  0.643924  79641.6\n",
       "3      AdaBoostClassifier  0.870582   0.783908  0.638696  81097.7\n",
       "4  RandomForestClassifier  0.850158   0.716068  0.626197  76481.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing potential customers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mouni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# Preprocess potential customers\n",
    "potential_customers = pd.read_excel(\"data/potential-customers.xlsx\", engine=\"openpyxl\")\n",
    "potential_customers = potential_customers.fillna(potential_customers.mode().iloc[0])\n",
    "to_label = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "for label in to_label:\n",
    "    potential_customers[label] = LabelEncoder().fit_transform(potential_customers[label])\n",
    "\n",
    "X_ = potential_customers.drop([\"RowID\"], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting labels for the potential customers using each classifier (with the best parameters) and also storing the estimate profit for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Estimated Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>183695.943313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>171551.137685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>169716.462628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>201972.915798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>181710.836760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Estimated Profit\n",
       "0    KNeighborsClassifier     183695.943313\n",
       "1  DecisionTreeClassifier     171551.137685\n",
       "2           CategoricalNB     169716.462628\n",
       "3      AdaBoostClassifier     201972.915798\n",
       "4  RandomForestClassifier     181710.836760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining all models with best parameters\n",
    "models = [KNeighborsClassifier(), DecisionTreeClassifier(criterion='entropy'), CategoricalNB(), AdaBoostClassifier(n_estimators=1000), RandomForestClassifier(n_estimators=1000)]\n",
    "profits_df = pd.DataFrame({\n",
    "    'Algorithm': ['KNeighborsClassifier', 'DecisionTreeClassifier', 'CategoricalNB', 'AdaBoostClassifier', 'RandomForestClassifier'],\n",
    "})\n",
    "profits = []\n",
    "# Training each one on the full dataset and predicting the labels for potential customers.\n",
    "# Using average precision from the evaluation to calculate an estimation of the profit.\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    precision = results.loc[i]['Precision']\n",
    "    model.fit(X, Y)\n",
    "    potential_customers[\"class\"] = model.predict(X_)\n",
    "    high_income = potential_customers[potential_customers[\"class\"] == 1]\n",
    "    low_income = potential_customers[potential_customers[\"class\"] == 0]\n",
    "    TP = precision*len(high_income)     # Estimated TP\n",
    "    FP = (1-precision)*len(high_income) # Estimated FP\n",
    "    estimated_profit = 0.1*TP*(980) + 0.05*FP*(-310) + (TP+FP)*(-10)\n",
    "    profits.append(estimated_profit)\n",
    "\n",
    "profits_df['Estimated Profit'] = profits\n",
    "\n",
    "display(profits_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save the row ids of the people that we are going to send the promotion to using the best performing classier (AdaBoost with 1000 estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(n_estimators=1000)\n",
    "model.fit(X, Y)\n",
    "high_income = potential_customers[potential_customers[\"class\"] == 1]\n",
    "np.savetxt('rows.txt', high_income['RowID'].values, fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
